{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Prompting\n",
    "\n",
    "A combination of several different kinds of prompting.  This is our own contribution, but it is a fairly obvious follow-up to the other prompt engineering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nPlease return an JSON string using the following format:\\n{\\n\"result\": 200, // an HTTPS result, either 200 or 503.\\n\"formatted-query\": \"!tsstart\" // PUT THE CORRECT COMMAND HERE\\n}\\nThe above JSON string states that first, the result is OK and the correctly formatted command.\\nThese commands are available:\\n- !transcribe [from-num-minutes-ago] (to-minutes-ago) // recall the transcription from X minutes ago up to Y minutes ago (Y is optional, defaults to 0).\\n- !transcribe [from-datetime] (to-datetime) // recall the transcription from the datetime X up to the datetime Y (Y is optional, defaults to now).\\n- !tsstart // start the transcription service\\n- !tsend // ends the transcription service\\n- !help // lists the available commands\\nA user is asking for: Recall the conversation between 80 and 90 minutes ago.\\nFind the relevant command and pass in the correct parameters. The parameters in these commands must be integers or dates.\\nUsing the relevant command and parameters, format a JSON string like we did above.\\n', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 512, 'num_predict': 256}}\n",
      "To find the relevant command and parameters to recall the conversation between 80 and 90 minutes ago, we would use the following command:\n",
      "\n",
      "!transcribe [from-num-minutes-ago] (to-minutes-ago)\n",
      "\n",
      "Here, from-num-minutes-ago is set to 80, and to-minutes-ago is set to 90. So, the full command is:\n",
      "```\n",
      "!transcribe 80 90\n",
      "```\n",
      "\n",
      "Now let's format a JSON string using this command:\n",
      "\n",
      "\n",
      "{\n",
      "\"result\": 200,\n",
      "\"formatted-query\": \"!transcribe 80 90\"\n",
      "}\n",
      "Time taken: 5.352s\n",
      "Final API request: {\n",
      "\"result\": 200,\n",
      "\"formatted-query\": \"!transcribe 80 90\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## HYBRID PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"Recall the conversation between 80 and 90 minutes ago.\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "PROMPT = \\\n",
    "\"\"\"\n",
    "Please return an JSON string using the following format:\n",
    "{\n",
    "\"result\": 200, // an HTTPS result, either 200 or 503.\n",
    "\"formatted-query\": \"!tsstart\" // PUT THE CORRECT COMMAND HERE\n",
    "}\n",
    "The above JSON string states that first, the result is OK and the correctly formatted command.\n",
    "These commands are available:\n",
    "- !transcribe [from-num-minutes-ago] (to-minutes-ago) // recall the transcription from X minutes ago up to Y minutes ago (Y is optional, defaults to 0).\n",
    "- !transcribe [from-datetime] (to-datetime) // recall the transcription from the datetime X up to the datetime Y (Y is optional, defaults to now).\n",
    "- !tsstart // start the transcription service\n",
    "- !tsend // ends the transcription service\n",
    "- !help // lists the available commands\n",
    "A user is asking for: %s\n",
    "Find the relevant command and pass in the correct parameters. The parameters in these commands must be integers or dates.\n",
    "Using the relevant command and parameters, format a JSON string like we did above.\n",
    "\"\"\" % MESSAGE\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=512, \n",
    "                         num_predict=256)\n",
    "\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n",
    "\n",
    "import re\n",
    "def extract_json(s):\n",
    "    match = re.search(r'\\{.*\\}', s, re.DOTALL)  # Find the first {...} block\n",
    "    return match.group(0) if match else None  # Return the JSON string or None if not found\n",
    "\n",
    "print(\"Final API request: %s\" % extract_json(response))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-eng-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
